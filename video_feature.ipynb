{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from time import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Mediapipe configurations\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp 데이터 프레임 정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video = '/Users/iduli/Desktop/Ch2_25_Scientific_Data/Final/raw_Dataset/SENSORS/VIDEO'\n",
    "raw_video_dir = os.path.join(Video, \"raw_video\")\n",
    "video_dir = os.path.join(Video)\n",
    "output_dir = os.path.join(Video, \"results\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 1st 폴더 처리\n",
    "folder_1st = os.path.join(raw_video_dir, \"1st\")\n",
    "time_csv_1st = os.path.join(video_dir, \"1st_time.csv\")\n",
    "\n",
    "# 2nd 폴더 처리\n",
    "folder_2nd = os.path.join(raw_video_dir, \"2nd\")\n",
    "time_csv_2nd = os.path.join(video_dir, \"2nd_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_time_for_condition(subject_num, condition, raw_audio_folder):\n",
    "    filename = f\"{subject_num}_1_{condition}_webcam-logger.csv\"\n",
    "    file_path = os.path.join(raw_audio_folder, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 첫 번째 행의 global_time을 baseline으로 사용\n",
    "    baseline_time = df.loc[0, \"global_time\"]\n",
    "    #print(baseline_time)\n",
    "    return baseline_time\n",
    "\n",
    "def parse_mmssms_to_timedelta(time_str):\n",
    "\n",
    "    if pd.isnull(time_str) or time_str.strip() == \"\":\n",
    "        return None\n",
    "    mm, ss, ms_str = time_str.split(\";\")\n",
    "    mm = int(mm)\n",
    "    ss = int(ss)\n",
    "    # '미리초(0~99)' * 10 => 실제 milliseconds\n",
    "    ms = int(ms_str) * 10\n",
    "    total_milliseconds = mm * 60000 + ss * 1000 + ms\n",
    "    #print(total_milliseconds)\n",
    "    return total_milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pnum            c1            c2            c3\n",
      "0      1 1708133022189 1708133874749 1708135064019\n",
      "1      2 1708138921695 1708139374615 1708139837415\n",
      "2      4 1708149174093 1708149673917 1708150138067\n",
      "3      5 1708154998132 1708155464002 1708156023392\n",
      "4      6 1708160855018 1708161215418 1708161682458\n",
      "5      7 1708220866360 1708221284930 1708221830720\n",
      "6      8 1708224638019 1708225072039 1708225517089\n",
      "7     10 1708236380941 1708236820081 1708237334871\n",
      "8     11 1708241795392 1708242291402 1708242944622\n",
      "9     12 1708307665621 1708308079571 1708308581531\n",
      "10    13 1708311237274 1708312013614 1708312435544\n",
      "11    14 1708316103451 1708316560461 1708317021341\n",
      "12    15 1708322961823 1708323444973 1708323913713\n"
     ]
    }
   ],
   "source": [
    "# 2nd \n",
    "time_df = pd.read_csv(time_csv_2nd)\n",
    "results = []\n",
    "for _, row in time_df.iterrows():\n",
    "    pnum = row[\"pnum\"]\n",
    "    condition = str(row[\"condition\"]).strip()\n",
    "    #print(pnum, condition)\n",
    "    c1_str = row[\"c1\"]\n",
    "    c2_str = row[\"c2\"]\n",
    "    c3_str = row[\"c3\"]\n",
    "    baseline = get_baseline_time_for_condition(pnum, condition, folder_2nd)\n",
    "    if baseline is None:\n",
    "        # 해당 파일이 없으면 None으로 두거나, 로그를 남길 수 있음\n",
    "        c1_utc = None\n",
    "        c2_utc = None\n",
    "        c3_utc = None\n",
    "    else:\n",
    "        # 2) c1, c2, c3 각각 파싱\n",
    "        \n",
    "        c1_offset = parse_mmssms_to_timedelta(c1_str)\n",
    "        c2_offset = parse_mmssms_to_timedelta(c2_str)\n",
    "        c3_offset = parse_mmssms_to_timedelta(c3_str)\n",
    "\n",
    "        c1_utc = int(baseline) + int(c1_offset) if c1_offset else None\n",
    "        c2_utc = int(baseline) + int(c2_offset) if c2_offset else None\n",
    "        c3_utc = int(baseline) + int(c3_offset) if c3_offset else None\n",
    "    results.append({\n",
    "        \"pnum\": pnum,\n",
    "        \"c1\": c1_utc,\n",
    "        \"c2\": c2_utc,\n",
    "        \"c3\": c3_utc\n",
    "    })\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.0f}')\n",
    "\n",
    "time_2 = pd.DataFrame(results)\n",
    "# pnum, condition 순으로 정렬\n",
    "time_2.sort_values(by=[\"pnum\"], inplace=True)\n",
    "time_2_grouped = time_2.groupby(\"pnum\", as_index=False).first()\n",
    "print(time_2_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pnum            c1            c2            c3\n",
      "0      1 1671068336785 1671068806645 1671069238335\n",
      "1      2 1671072379186 1671072795326 1671073226566\n",
      "2      3 1671078713202 1671080082890 1671079535240\n",
      "3      4 1671083392936 1671083821136 1671084427321\n",
      "4      8 1671167300402 1671167843772 1671168355472\n",
      "5     10 1671176153254 1671176527614 1671176950044\n",
      "6     12 1671245406272 1671245867362 1671246283292\n",
      "7     13 1671251228083 1671251839213 1671252301653\n",
      "8     14 1671256497984 1671256889694 1671257299414\n",
      "9     16 1671267813860 1671268230560 1671268630930\n",
      "10    18 1671332110114 1671332508724 1671332923974\n",
      "11    19 1671337390010 1671337759720 1671338152320\n",
      "12    20 1671343176119 1671343685068 1671344101538\n",
      "13    21 1671348410357 1671348821827 1671349396847\n",
      "14    22 1671353003060 1671353409090 1671353984170\n",
      "15    23 1671429960227 1671430379247 1671430797957\n",
      "16    25 1671587643730 1671588031700 1671588539130\n",
      "17    26 1671672896380 1671673328260 1671673828350\n",
      "18    27 1671688733167 1671689139997 1671689532707\n"
     ]
    }
   ],
   "source": [
    "# 2nd \n",
    "time_df = pd.read_csv(time_csv_1st)\n",
    "results = []\n",
    "for _, row in time_df.iterrows():\n",
    "    pnum = row[\"pnum\"]\n",
    "    condition = str(row[\"condition\"]).strip()\n",
    "    #print(pnum, condition)\n",
    "    c1_str = row[\"c1\"]\n",
    "    c2_str = row[\"c2\"]\n",
    "    c3_str = row[\"c3\"]\n",
    "    baseline = get_baseline_time_for_condition(pnum, condition, folder_1st)\n",
    "    if baseline is None:\n",
    "        # 해당 파일이 없으면 None으로 두거나, 로그를 남길 수 있음\n",
    "        c1_utc = None\n",
    "        c2_utc = None\n",
    "        c3_utc = None\n",
    "    else:\n",
    "        # 2) c1, c2, c3 각각 파싱\n",
    "        \n",
    "        c1_offset = parse_mmssms_to_timedelta(c1_str)\n",
    "        c2_offset = parse_mmssms_to_timedelta(c2_str)\n",
    "        c3_offset = parse_mmssms_to_timedelta(c3_str)\n",
    "\n",
    "        c1_utc = int(baseline) + int(c1_offset) if c1_offset else None\n",
    "        c2_utc = int(baseline) + int(c2_offset) if c2_offset else None\n",
    "        c3_utc = int(baseline) + int(c3_offset) if c3_offset else None\n",
    "    results.append({\n",
    "        \"pnum\": pnum,\n",
    "        \"c1\": c1_utc,\n",
    "        \"c2\": c2_utc,\n",
    "        \"c3\": c3_utc\n",
    "    })\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.0f}')\n",
    "\n",
    "time_1 = pd.DataFrame(results)\n",
    "# pnum, condition 순으로 정렬\n",
    "time_1.sort_values(by=[\"pnum\"], inplace=True)\n",
    "time_1_grouped = time_1.groupby(\"pnum\", as_index=False).first()\n",
    "\n",
    "print(time_1_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = '/Users/iduli/Desktop/Ch2_25_Scientific_Data/Final/raw_Dataset/SENSORS/VIDEO/parsed_video/2nd'\n",
    "result_folder = '/Users/iduli/Desktop/Ch2_25_Scientific_Data/Final/raw_Dataset/SENSORS/VIDEO/features/2nd'\n",
    "\n",
    "# Mediapipe, OpenCV and interval configurations\n",
    "EAR_THRESHOLD = 0.3\n",
    "FOURCC = 'XVID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features_to_csv(df_features, file_path):\n",
    "    df_features.to_csv(file_path, index=False)\n",
    "\n",
    "# Calculate the eye aspect ratio\n",
    "def calculate_eye_aspect_ratio(eye_landmarks):\n",
    "    A = np.linalg.norm(eye_landmarks[1] - eye_landmarks[5])\n",
    "    B = np.linalg.norm(eye_landmarks[2] - eye_landmarks[4])\n",
    "    C = np.linalg.norm(eye_landmarks[0] - eye_landmarks[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "# Calculate the distance between two points\n",
    "def normalize_vector(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0:\n",
    "        return v\n",
    "    return v / norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path):\n",
    "    frame_idx = 0\n",
    "    frame_time = 0\n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Cannot open video {video_path}\")\n",
    "        return None    \n",
    "    folder_path, video_file = os.path.split(video_path)\n",
    "    print(video_file)\n",
    "    base_name = os.path.splitext(video_file)[0]\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    # Initialize variables\n",
    "    feature_list = []\n",
    "    prev_lip_corner_left, prev_lip_corner_right = None, None\n",
    "    prev_left_eye_aspect_ratio, prev_right_eye_aspect_ratio = None, None\n",
    "    blink_count = 0\n",
    "\n",
    "    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.7) as face_detection, \\\n",
    "         mp_face_mesh.FaceMesh(min_detection_confidence=0.7, min_tracking_confidence=0.7, refine_landmarks= True) as face_mesh:\n",
    "        #print(frame_idx)\n",
    "        while cap.isOpened():\n",
    "            # Set frame time, will be added after 영상 시작시간  \n",
    "            #current_frame_idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            #print(current_frame_idx) frame 0 1 같은시간 읽어짐. \n",
    "            frame_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            success, image = cap.read()\n",
    "            error_type = 0\n",
    "            if not success:\n",
    "                # Case 1: 프레임 읽기 실패\n",
    "                error_type = 1\n",
    "                frame_features = [frame_time, np.nan, np.nan, np.nan, np.nan,\n",
    "                                  np.nan, np.nan, np.nan, np.nan, np.nan, error_type]  \n",
    "                break\n",
    "\n",
    "            # Convert BGR to RGB for Mediapipe\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image_rgb.flags.writeable = False\n",
    "\n",
    "            # Process face detection and face mesh\n",
    "            results = face_detection.process(image_rgb)\n",
    "            mesh_results = face_mesh.process(image_rgb)\n",
    "\n",
    "            if not results.detections:\n",
    "                # Case 2: 얼굴 탐지 실패\n",
    "                error_type = 2\n",
    "                frame_features = [frame_time, np.nan, np.nan, np.nan, np.nan,\n",
    "                                  np.nan, np.nan, np.nan, np.nan, np.nan, error_type]  \n",
    "                feature_list.append(frame_features)\n",
    "                continue\n",
    "\n",
    "            # Convert RGB back to BGR for OpenCV\n",
    "            image_rgb.flags.writeable = True\n",
    "            image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Initialize default values\n",
    "            rotation_x, rotation_y, rotation_z = np.nan, np.nan, np.nan\n",
    "            total_translation = np.nan\n",
    "            gaze_direction = np.array([np.nan, np.nan])\n",
    "            left_lip_movement, right_lip_movement = np.nan, np.nan\n",
    "\n",
    "            # Process face detection\n",
    "            if results.detections:\n",
    "                largest_face = max(results.detections, key=lambda detection: detection.location_data.relative_bounding_box.width * detection.location_data.relative_bounding_box.height)\n",
    "                blink_count = 0  # Reset blink count for each frame\n",
    "\n",
    "            # Process face mesh landmarks\n",
    "            if mesh_results.multi_face_landmarks:\n",
    "                for face_landmarks in mesh_results.multi_face_landmarks:\n",
    "                    landmarks = np.array([(lm.x, lm.y, lm.z) for lm in face_landmarks.landmark])\n",
    "\n",
    "                    # Calculate head movement\n",
    "                    image_points = np.array([\n",
    "                        (landmarks[1][0] * image.shape[1], landmarks[1][1] * image.shape[0]),\n",
    "                        (landmarks[33][0] * image.shape[1], landmarks[33][1] * image.shape[0]),\n",
    "                        (landmarks[263][0] * image.shape[1], landmarks[263][1] * image.shape[0]),\n",
    "                        (landmarks[61][0] * image.shape[1], landmarks[61][1] * image.shape[0]),\n",
    "                        (landmarks[291][0] * image.shape[1], landmarks[291][1] * image.shape[0]),\n",
    "                        (landmarks[199][0] * image.shape[1], landmarks[199][1] * image.shape[0])\n",
    "                    ], dtype=\"double\")\n",
    "\n",
    "                    '''considering changing the points from static value to dynamic value based on landmarks'''\n",
    "                    model_points = np.array([\n",
    "                        (0.0, 0.0, 0.0),\n",
    "                        (-30.0, -125.0, -30.0),\n",
    "                        (30.0, -125.0, -30.0),\n",
    "                        (-60.0, -70.0, -60.0),\n",
    "                        (60.0, -70.0, -60.0),\n",
    "                        (0.0, -150.0, -100.0)\n",
    "                    ]) \n",
    "                    '''model_points = np.array([\n",
    "                                    (landmarks[1][0], landmarks[1][1], landmarks[1][2]),    # 코 끝\n",
    "                                    (landmarks[33][0], landmarks[33][1], landmarks[33][2]), # 왼쪽 눈\n",
    "                                    (landmarks[263][0], landmarks[263][1], landmarks[263][2]), # 오른쪽 눈\n",
    "                                    (landmarks[61][0], landmarks[61][1], landmarks[61][2]), # 왼쪽 입술\n",
    "                                    (landmarks[291][0], landmarks[291][1], landmarks[291][2]), # 오른쪽 입술\n",
    "                                    (landmarks[199][0], landmarks[199][1], landmarks[199][2])  # 턱 끝\n",
    "                                ])'''\n",
    "                    size = image.shape\n",
    "                    focal_length = size[1]\n",
    "                    print(focal_length)\n",
    "                    center = (size[1] / 2, size[0] / 2)\n",
    "                    camera_matrix = np.array([\n",
    "                        [focal_length, 0, center[0]],\n",
    "                        [0, focal_length, center[1]],\n",
    "                        [0, 0, 1]\n",
    "                    ], dtype=\"double\")\n",
    "                    print(center[0])\n",
    "\n",
    "                    dist_coeffs = np.zeros((4, 1))\n",
    "                    success, rotation_vector, translation_vector = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n",
    "\n",
    "                    if success:\n",
    "                        rotation_x, rotation_y, rotation_z = rotation_vector.ravel()\n",
    "                        total_translation = np.linalg.norm(translation_vector)\n",
    "                        #print('head')\n",
    "\n",
    "                        # Calculate eye aspect ratio\n",
    "                        left_eye_landmarks = landmarks[[33, 160, 158, 133, 153, 144]]\n",
    "                        right_eye_landmarks = landmarks[[362, 385, 387, 263, 373, 380]]\n",
    "                        left_ear = calculate_eye_aspect_ratio(left_eye_landmarks)\n",
    "                        right_ear = calculate_eye_aspect_ratio(right_eye_landmarks)\n",
    "\n",
    "                        if prev_left_eye_aspect_ratio is not None and prev_right_eye_aspect_ratio is not None:\n",
    "                            if (left_ear < EAR_THRESHOLD and prev_left_eye_aspect_ratio >= EAR_THRESHOLD) or \\\n",
    "                               (right_ear < EAR_THRESHOLD and prev_right_eye_aspect_ratio >= EAR_THRESHOLD):\n",
    "                                blink_count += 1\n",
    "                        #print('eye')\n",
    "\n",
    "                        prev_left_eye_aspect_ratio = left_ear\n",
    "                        prev_right_eye_aspect_ratio = right_ear\n",
    "\n",
    "                        # Calculate gaze direction\n",
    "                        \n",
    "                        left_iris_center = np.mean(landmarks[[474, 475, 476, 477]], axis=0)\n",
    "                        right_iris_center = np.mean(landmarks[[469, 470, 471, 472]], axis=0)\n",
    "                        nose_tip = landmarks[1]\n",
    "                        gaze_direction = normalize_vector((left_iris_center + right_iris_center) / 2.0 - nose_tip)\n",
    "                        #print('gaze')\n",
    "                        # Calculate lip movement\n",
    "                        left_lip_corner = landmarks[61]\n",
    "                        right_lip_corner = landmarks[291]\n",
    "                        if prev_lip_corner_left is not None and prev_lip_corner_right is not None:\n",
    "                            left_lip_movement = np.linalg.norm(left_lip_corner - nose_tip) - np.linalg.norm(prev_lip_corner_left - nose_tip)\n",
    "                            right_lip_movement = np.linalg.norm(right_lip_corner - nose_tip) - np.linalg.norm(prev_lip_corner_right - nose_tip)\n",
    "                        #print('lip')\n",
    "                        prev_lip_corner_left = left_lip_corner\n",
    "                        prev_lip_corner_right = right_lip_corner\n",
    "            # Append features\n",
    "            frame_features = [frame_time, rotation_x, rotation_y, rotation_z, total_translation,\n",
    "                              gaze_direction[0], gaze_direction[1], left_lip_movement, right_lip_movement, blink_count, error_type]\n",
    "\n",
    "            feature_list.append(frame_features)\n",
    "            frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    csv_file_path = os.path.join(result_folder, f'{base_name}.csv')\n",
    "    save_features_to_csv(pd.DataFrame(feature_list, columns=[\n",
    "        \"Timestamp\", \"rotation_x\", \"rotation_y\", \"rotation_z\",\n",
    "        \"Total Movement\", \"Gaze X\", \"Gaze Y\",\n",
    "        \"Left Lip Movement\", \"Right Lip Movement\",\n",
    "        \"Blink Count\",'error_type']), csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "process_video('/Users/iduli/Desktop/Ch2_25_Scientific_Data/Final/raw_Dataset/SENSORS/VIDEO/parsed_video/2nd/3_c1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(video_folder): \n",
    "    process_video(os.path.join(video_folder,file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
